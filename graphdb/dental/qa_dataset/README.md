# ë‚œì´ë„ë³„ QA ë°ì´í„°ì…‹

SNOMED CT ì¹˜ê³¼ ì„œë¸Œê·¸ë˜í”„ì—ì„œ ìë™ ìƒì„±ëœ ë‚œì´ë„ë³„ QA ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.

## ğŸ“Š ë°ì´í„°ì…‹ í†µê³„

- **ì´ QA ìŒ**: 621ê°œ
- **ë‚œì´ë„ë³„ ë¶„í¬**:
  - ì‰¬ì›€ (Level 1): 221ê°œ (35.6%)
  - ì¤‘ê°„ (Level 2): 200ê°œ (32.2%)
  - ì–´ë ¤ì›€ (Level 3+): 200ê°œ (32.2%)

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
qa_dataset/
â”œâ”€â”€ qa_all.jsonl        # ì „ì²´ QA ë°ì´í„°ì…‹ (621ê°œ)
â”œâ”€â”€ qa_level1.jsonl     # Level 1: ë‹¨ìˆœ 1-hop (221ê°œ)
â”œâ”€â”€ qa_level2.jsonl     # Level 2: 2-hop ì¶”ë¡  (200ê°œ)
â”œâ”€â”€ qa_level3.jsonl     # Level 3: 3+ hop ì¶”ë¡  (100ê°œ)
â”œâ”€â”€ qa_complex.jsonl    # ë³µí•© ì œì•½ ì¡°ê±´ QA (100ê°œ)
â””â”€â”€ qa_stats.json       # í†µê³„ ì •ë³´
```

## ğŸ¯ ë‚œì´ë„ë³„ ì„¤ëª…

### Level 1 (ì‰¬ì›€) - ë‹¨ìˆœ 1-hop ì‚¬ì‹¤ ê²€ìƒ‰

ì§ì ‘ ì—°ê²°ëœ ê´€ê³„ë¥¼ ë¬»ëŠ” ë‹¨ìˆœí•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.

**ê´€ê³„ íƒ€ì… ë¶„í¬**:
- IS_A: 65ê°œ (29.4%)
- FINDING_SITE: 51ê°œ (23.1%)
- CAUSATIVE_AGENT: 36ê°œ (16.3%)
- PATHOLOGICAL_PROCESS: 36ê°œ (16.3%)
- ASSOCIATED_MORPHOLOGY: 33ê°œ (14.9%)

**ì˜ˆì‹œ**:
```json
{
  "question": "ì¹˜ì•„ ìš°ì‹ì¦ì˜ ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?",
  "answer": "ì¹˜ì•„ ìš°ì‹ì¦ì˜ ì£¼ìš” ì›ì¸ì€ ë°•í…Œë¦¬ì•„ì…ë‹ˆë‹¤.",
  "level": 1,
  "difficulty": "easy",
  "relation_type": "CAUSATIVE_AGENT"
}
```

**í‰ê·  ê¸¸ì´**:
- ì§ˆë¬¸: 75.2ì
- ë‹µë³€: 109.7ì

### Level 2 (ì¤‘ê°„) - 2-hop ë‹¤ë‹¨ê³„ ì¶”ë¡ 

ì¤‘ê°„ ê°œë…ì„ ê±°ì³ ì—°ê²°ëœ ê´€ê³„ë¥¼ ì´í•´í•´ì•¼ í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.

**ì£¼ìš” ê´€ê³„ ì¡°í•©**:
- IS_A â†’ IS_A: 36ê°œ
- IS_A â†’ FINDING_SITE: 32ê°œ
- DUE_TO â†’ IS_A: 32ê°œ
- IS_A â†’ PATHOLOGICAL_PROCESS: 21ê°œ
- IS_A â†’ CAUSATIVE_AGENT: 21ê°œ

**ì˜ˆì‹œ**:
```json
{
  "question": "ì¹˜ì•„ ìš°ì‹ì¦ì˜ ìƒìœ„ ê°œë…ì˜ ë°œìƒ ë¶€ìœ„ëŠ”?",
  "answer": "ì¹˜ì•„ ìš°ì‹ì¦ì˜ ìƒìœ„ ê°œë…ì€ ì¹˜ì•„ ì§ˆí™˜ì´ê³ , ì´ê²ƒì˜ ë°œìƒ ë¶€ìœ„ëŠ” êµ¬ê°•ì…ë‹ˆë‹¤.",
  "level": 2,
  "difficulty": "medium",
  "metadata": {
    "relations": ["IS_A", "FINDING_SITE"],
    "path": "ì¹˜ì•„ ìš°ì‹ì¦ -> ì¹˜ì•„ ì§ˆí™˜ -> êµ¬ê°•"
  }
}
```

**í‰ê·  ê¸¸ì´**:
- ì§ˆë¬¸: 135.3ì
- ë‹µë³€: 172.5ì

### Level 3 (ì–´ë ¤ì›€) - 3+ hop ë³µì¡í•œ ì¶”ë¡ 

ì—¬ëŸ¬ ë‹¨ê³„ì˜ ê´€ê³„ë¥¼ í†µí•´ ì—°ê²°ëœ ê°œë…ë“¤ì„ ì´í•´í•´ì•¼ í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤.

**Hop ìˆ˜ ë¶„í¬**:
- 3-hop: 100ê°œ

**ì˜ˆì‹œ**:
```json
{
  "question": "ì¹˜ì•„ ìš°ì‹ì¦ì—ì„œ 3ë‹¨ê³„ ê´€ê³„ë¥¼ í†µí•´ ì—°ê²°ëœ ê°œë…ì€?",
  "answer": "ì¹˜ì•„ ìš°ì‹ì¦ì€ ì¹˜ì•„ ì§ˆí™˜ -> êµ¬ê°• ì§ˆí™˜ì„ ê±°ì³ ê°ì—¼ì„± ì§ˆí™˜ê³¼ ì—°ê²°ë©ë‹ˆë‹¤.",
  "level": 3,
  "difficulty": "hard",
  "metadata": {
    "hops": 3,
    "relations": ["IS_A", "IS_A", "PATHOLOGICAL_PROCESS"]
  }
}
```

**í‰ê·  ê¸¸ì´**:
- ì§ˆë¬¸: 71.7ì
- ë‹µë³€: 162.3ì

### ë³µí•© QA - ì—¬ëŸ¬ ì œì•½ ì¡°ê±´

ì—¬ëŸ¬ ê´€ê³„ë¥¼ ë™ì‹œì— ê³ ë ¤í•´ì•¼ í•˜ëŠ” ë³µì¡í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.

**íŠ¹ì§•**:
- ì›ì¸(CAUSATIVE_AGENT)ê³¼ ë¶€ìœ„(FINDING_SITE)ë¥¼ ë™ì‹œì— ì œì•½
- ì—­ë°©í–¥ ì¶”ë¡  í•„ìš”

**ì˜ˆì‹œ**:
```json
{
  "question": "ì›ì¸ì´ ë°•í…Œë¦¬ì•„ì´ê³  ì¹˜ì•„ì—ì„œ ë°œìƒí•˜ëŠ” ì§ˆë³‘ì€?",
  "answer": "ì¹˜ì•„ ìš°ì‹ì¦ì€ ë°•í…Œë¦¬ì•„ê°€ ì›ì¸ì´ë©° ì¹˜ì•„ì—ì„œ ë°œìƒí•˜ëŠ” ì§ˆë³‘ì…ë‹ˆë‹¤.",
  "level": 3,
  "difficulty": "hard",
  "type": "complex",
  "metadata": {
    "causative_agent": "Bacterium (organism)",
    "finding_site": "Structure of hard tissue of tooth",
    "query_type": "multi_constraint"
  }
}
```

**í‰ê·  ê¸¸ì´**:
- ì§ˆë¬¸: 84.8ì
- ë‹µë³€: 138.0ì

## ğŸ’¡ ì‚¬ìš© ë°©ë²•

### Pythonìœ¼ë¡œ ë¡œë“œ

```python
import json

# JSONL íŒŒì¼ ë¡œë“œ
def load_qa_dataset(file_path):
    qa_list = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            qa_list.append(json.loads(line))
    return qa_list

# Level 1 ë°ì´í„° ë¡œë“œ
level1_qa = load_qa_dataset('qa_dataset/qa_level1.jsonl')

# ì˜ˆì‹œ ì¶œë ¥
for qa in level1_qa[:3]:
    print(f"Q: {qa['question']}")
    print(f"A: {qa['answer']}")
    print(f"Level: {qa['level']}, Difficulty: {qa['difficulty']}")
    print()
```

### Curriculum Learningì— í™œìš©

ë‚œì´ë„ ìˆœì„œëŒ€ë¡œ í•™ìŠµ:

```python
# 1. Level 1ë¡œ ê¸°ë³¸ ê°œë… í•™ìŠµ
train_on_dataset('qa_level1.jsonl', epochs=3)

# 2. Level 2ë¡œ ì¶”ë¡  ëŠ¥ë ¥ í–¥ìƒ
train_on_dataset('qa_level2.jsonl', epochs=2)

# 3. Level 3ë¡œ ë³µì¡í•œ ì¶”ë¡  í•™ìŠµ
train_on_dataset('qa_level3.jsonl', epochs=2)

# 4. Complex QAë¡œ ì¢…í•© ëŠ¥ë ¥ í–¥ìƒ
train_on_dataset('qa_complex.jsonl', epochs=1)
```

## ğŸ“ˆ í’ˆì§ˆ ê´€ë¦¬

### ìë™ ìƒì„± ê¸°ì¤€
- âœ… SNOMED CTì˜ ê³µì‹ ê´€ê³„ í™œìš©
- âœ… ì‚¬ì „ ì •ì˜ëœ QA í…œí”Œë¦¿ ì‚¬ìš©
- âœ… ê´€ê³„ íƒ€ì…ë³„ ë‹¤ì–‘í•œ ì§ˆë¬¸ í˜•ì‹
- âœ… ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ì  ê°€ëŠ¥

### ì œí•œì‚¬í•­
- ìš©ì–´ê°€ ê¸¸ê³  ì „ë¬¸ì  (SNOMED CT ìš©ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ í‘œí˜„ ê°œì„  í•„ìš”
- ì¼ë¶€ QAëŠ” ì‚¬ëŒì˜ ê²€ìˆ˜ ê¶Œì¥

## ğŸ”„ ë°ì´í„°ì…‹ ì¬ìƒì„±

```bash
# ê¸°ë³¸ ìƒì„± (ì´ 621ê°œ)
python generate_qa_dataset.py --output-dir ./qa_dataset

# ìƒ˜í”Œ ìˆ˜ ì¡°ì •
python generate_qa_dataset.py \
  --level1 1000 \
  --level2 500 \
  --level3 200 \
  --complex 200 \
  --output-dir ./qa_dataset

# ë¶„ì„ ë° ìƒ˜í”Œ ì¶œë ¥
python analyze_qa_dataset.py --export-samples
```

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„

1. **ë°ì´í„° ì •ì œ**: ìš©ì–´ ë‹¨ìˆœí™”, ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ê°œì„ 
2. **ë°ì´í„° ì¦ê°•**: 
   - íŒ¨ëŸ¬í”„ë ˆì´ì§•ìœ¼ë¡œ ì§ˆë¬¸ ë‹¤ì–‘í™”
   - ë¶€ì • ì˜ˆì œ ì¶”ê°€ (ì˜ëª»ëœ ë‹µë³€)
3. **Curriculum Learning**: ë‚œì´ë„ ìˆœì„œëŒ€ë¡œ í•™ìŠµ
4. **DPO/RLHF**: ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ê°€ í•™ìŠµ
5. **í‰ê°€ ë°ì´í„°ì…‹**: ë³„ë„ì˜ Test Set ìƒì„±

## ğŸ“– ì°¸ê³ 

- ìƒì„± ìŠ¤í¬ë¦½íŠ¸: `generate_qa_dataset.py`
- ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸: `analyze_qa_dataset.py`
- Neo4j ì¿¼ë¦¬: `neo4j_query_utils.py`

