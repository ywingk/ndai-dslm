"""
QA ë°ì´í„°ì…‹ ë¶„ì„ ë° ì‹œê°í™”
-------------------------
ìƒì„±ëœ QA ë°ì´í„°ì…‹ì˜ í†µê³„ì™€ ì˜ˆì‹œë¥¼ í™•ì¸
"""
import json
import os
from collections import Counter
from typing import List, Dict


def load_jsonl(file_path: str) -> List[Dict]:
    """JSONL íŒŒì¼ ë¡œë“œ"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            data.append(json.loads(line))
    return data


def analyze_qa_dataset(dataset_dir: str = "./qa_dataset"):
    """QA ë°ì´í„°ì…‹ ë¶„ì„"""
    print("=" * 80)
    print("ğŸ“Š QA ë°ì´í„°ì…‹ ë¶„ì„")
    print("=" * 80)
    
    # í†µê³„ ë¡œë“œ
    stats_file = os.path.join(dataset_dir, "qa_stats.json")
    with open(stats_file, 'r') as f:
        stats = json.load(f)
    
    print(f"\nğŸ“ˆ ì „ì²´ í†µê³„:")
    print(f"  - ì´ QA ìŒ: {stats['total']}ê°œ")
    print(f"\në‚œì´ë„ë³„ ë¶„í¬:")
    print(f"  - ì‰¬ì›€ (Level 1): {stats['by_difficulty']['easy']}ê°œ ({stats['by_difficulty']['easy']/stats['total']*100:.1f}%)")
    print(f"  - ì¤‘ê°„ (Level 2): {stats['by_difficulty']['medium']}ê°œ ({stats['by_difficulty']['medium']/stats['total']*100:.1f}%)")
    print(f"  - ì–´ë ¤ì›€ (Level 3+): {stats['by_difficulty']['hard']}ê°œ ({stats['by_difficulty']['hard']/stats['total']*100:.1f}%)")
    
    # Level 1 ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ“Œ Level 1 (ì‰¬ì›€) - ë‹¨ìˆœ 1-hop ì‚¬ì‹¤ ê²€ìƒ‰")
    print("=" * 80)
    
    level1_data = load_jsonl(os.path.join(dataset_dir, "qa_level1.jsonl"))
    
    # ê´€ê³„ íƒ€ì… ë¶„í¬
    relation_types = Counter([qa['relation_type'] for qa in level1_data])
    print(f"\nê´€ê³„ íƒ€ì… ë¶„í¬:")
    for rel_type, count in relation_types.most_common():
        print(f"  - {rel_type}: {count}ê°œ ({count/len(level1_data)*100:.1f}%)")
    
    # ì˜ˆì‹œ
    print(f"\nì˜ˆì‹œ (3ê°œ):")
    for i, qa in enumerate(level1_data[:3], 1):
        print(f"\n  [{i}] {qa['relation_type']}")
        print(f"      Q: {qa['question']}")
        print(f"      A: {qa['answer']}")
    
    # Level 2 ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ“Œ Level 2 (ì¤‘ê°„) - 2-hop ë‹¤ë‹¨ê³„ ì¶”ë¡ ")
    print("=" * 80)
    
    level2_data = load_jsonl(os.path.join(dataset_dir, "qa_level2.jsonl"))
    
    # ê´€ê³„ ì¡°í•© ë¶„ì„
    relation_combos = Counter([
        " -> ".join(qa['metadata']['relations']) 
        for qa in level2_data
    ])
    print(f"\nê´€ê³„ ì¡°í•© Top 5:")
    for combo, count in relation_combos.most_common(5):
        print(f"  - {combo}: {count}ê°œ")
    
    # ì˜ˆì‹œ
    print(f"\nì˜ˆì‹œ (2ê°œ):")
    for i, qa in enumerate(level2_data[:2], 1):
        print(f"\n  [{i}] ê²½ë¡œ: {' -> '.join(qa['metadata']['relations'])}")
        print(f"      Q: {qa['question']}")
        print(f"      A: {qa['answer']}")
    
    # Level 3 ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ“Œ Level 3 (ì–´ë ¤ì›€) - 3+ hop ë³µì¡í•œ ì¶”ë¡ ")
    print("=" * 80)
    
    level3_data = load_jsonl(os.path.join(dataset_dir, "qa_level3.jsonl"))
    
    # hop ìˆ˜ ë¶„í¬
    hop_counts = Counter([qa['metadata']['hops'] for qa in level3_data])
    print(f"\nHop ìˆ˜ ë¶„í¬:")
    for hops, count in sorted(hop_counts.items()):
        print(f"  - {hops}-hop: {count}ê°œ")
    
    # ì˜ˆì‹œ
    print(f"\nì˜ˆì‹œ (2ê°œ):")
    for i, qa in enumerate(level3_data[:2], 1):
        print(f"\n  [{i}] {qa['metadata']['hops']}-hop")
        print(f"      ê²½ë¡œ: {qa['metadata']['path']}")
        print(f"      Q: {qa['question'][:100]}...")
        print(f"      A: {qa['answer'][:100]}...")
    
    # Complex QA ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ“Œ ë³µí•© QA - ì—¬ëŸ¬ ì œì•½ ì¡°ê±´")
    print("=" * 80)
    
    complex_data = load_jsonl(os.path.join(dataset_dir, "qa_complex.jsonl"))
    
    print(f"\nì´ {len(complex_data)}ê°œì˜ ë³µí•© QA")
    
    # ì˜ˆì‹œ
    print(f"\nì˜ˆì‹œ (2ê°œ):")
    for i, qa in enumerate(complex_data[:2], 1):
        print(f"\n  [{i}] ë³µí•© ì œì•½")
        print(f"      ì›ì¸: {qa['metadata']['causative_agent']}")
        print(f"      ë¶€ìœ„: {qa['metadata']['finding_site']}")
        print(f"      Q: {qa['question']}")
        print(f"      A: {qa['answer']}")
    
    # ë‚œì´ë„ë³„ ì§ˆë¬¸ ê¸¸ì´ ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ“Š ì§ˆë¬¸/ë‹µë³€ ê¸¸ì´ ë¶„ì„")
    print("=" * 80)
    
    all_data = {
        "Level 1": level1_data,
        "Level 2": level2_data,
        "Level 3": level3_data,
        "Complex": complex_data
    }
    
    for level_name, data in all_data.items():
        avg_q_len = sum(len(qa['question']) for qa in data) / len(data)
        avg_a_len = sum(len(qa['answer']) for qa in data) / len(data)
        print(f"\n{level_name}:")
        print(f"  - í‰ê·  ì§ˆë¬¸ ê¸¸ì´: {avg_q_len:.1f}ì")
        print(f"  - í‰ê·  ë‹µë³€ ê¸¸ì´: {avg_a_len:.1f}ì")
    
    print("\n" + "=" * 80)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("=" * 80)


def export_samples(dataset_dir: str = "./qa_dataset", 
                   output_file: str = "./qa_samples.md"):
    """ìƒ˜í”Œ QAë¥¼ Markdownìœ¼ë¡œ ì¶œë ¥"""
    print(f"\nğŸ“ ìƒ˜í”Œ QAë¥¼ {output_file}ë¡œ ì¶œë ¥ ì¤‘...")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# QA ë°ì´í„°ì…‹ ìƒ˜í”Œ\n\n")
        
        # Level 1
        f.write("## Level 1 (ì‰¬ì›€) - ë‹¨ìˆœ 1-hop ì‚¬ì‹¤ ê²€ìƒ‰\n\n")
        level1_data = load_jsonl(os.path.join(dataset_dir, "qa_level1.jsonl"))
        for i, qa in enumerate(level1_data[:5], 1):
            f.write(f"### ì˜ˆì‹œ {i}: {qa['relation_type']}\n\n")
            f.write(f"**Q:** {qa['question']}\n\n")
            f.write(f"**A:** {qa['answer']}\n\n")
            f.write(f"- ë‚œì´ë„: {qa['difficulty']}\n")
            f.write(f"- ê´€ê³„: {qa['relation_type']}\n\n")
            f.write("---\n\n")
        
        # Level 2
        f.write("## Level 2 (ì¤‘ê°„) - 2-hop ë‹¤ë‹¨ê³„ ì¶”ë¡ \n\n")
        level2_data = load_jsonl(os.path.join(dataset_dir, "qa_level2.jsonl"))
        for i, qa in enumerate(level2_data[:5], 1):
            f.write(f"### ì˜ˆì‹œ {i}\n\n")
            f.write(f"**Q:** {qa['question']}\n\n")
            f.write(f"**A:** {qa['answer']}\n\n")
            f.write(f"- ë‚œì´ë„: {qa['difficulty']}\n")
            f.write(f"- ê²½ë¡œ: {qa['metadata']['path']}\n\n")
            f.write("---\n\n")
        
        # Level 3
        f.write("## Level 3 (ì–´ë ¤ì›€) - 3+ hop ë³µì¡í•œ ì¶”ë¡ \n\n")
        level3_data = load_jsonl(os.path.join(dataset_dir, "qa_level3.jsonl"))
        for i, qa in enumerate(level3_data[:5], 1):
            f.write(f"### ì˜ˆì‹œ {i}\n\n")
            f.write(f"**Q:** {qa['question']}\n\n")
            f.write(f"**A:** {qa['answer']}\n\n")
            f.write(f"- ë‚œì´ë„: {qa['difficulty']}\n")
            f.write(f"- Hop ìˆ˜: {qa['metadata']['hops']}\n")
            f.write(f"- ê²½ë¡œ: {qa['metadata']['path']}\n\n")
            f.write("---\n\n")
        
        # Complex
        f.write("## ë³µí•© QA - ì—¬ëŸ¬ ì œì•½ ì¡°ê±´\n\n")
        complex_data = load_jsonl(os.path.join(dataset_dir, "qa_complex.jsonl"))
        for i, qa in enumerate(complex_data[:5], 1):
            f.write(f"### ì˜ˆì‹œ {i}\n\n")
            f.write(f"**Q:** {qa['question']}\n\n")
            f.write(f"**A:** {qa['answer']}\n\n")
            f.write(f"- ë‚œì´ë„: {qa['difficulty']}\n")
            f.write(f"- ì›ì¸: {qa['metadata']['causative_agent']}\n")
            f.write(f"- ë¶€ìœ„: {qa['metadata']['finding_site']}\n\n")
            f.write("---\n\n")
    
    print(f"âœ… {output_file} ìƒì„± ì™„ë£Œ")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="QA ë°ì´í„°ì…‹ ë¶„ì„")
    parser.add_argument("--dataset-dir", default="./qa_dataset", help="ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬")
    parser.add_argument("--export-samples", action="store_true", help="ìƒ˜í”Œì„ Markdownìœ¼ë¡œ ì¶œë ¥")
    
    args = parser.parse_args()
    
    # ë¶„ì„ ì‹¤í–‰
    analyze_qa_dataset(args.dataset_dir)
    
    # ìƒ˜í”Œ ì¶œë ¥
    if args.export_samples:
        export_samples(args.dataset_dir, "./qa_samples.md")


if __name__ == "__main__":
    main()

