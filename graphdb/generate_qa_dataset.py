"""
Neo4jì—ì„œ ë‚œì´ë„ë³„ QA ë°ì´í„°ì…‹ ìƒì„±
------------------------------------
SNOMED CT ê·¸ë˜í”„ì—ì„œ 1-hop, 2-hop, 3-hop ê´€ê³„ë¥¼ ì´ìš©í•œ
ë‚œì´ë„ë³„ QA ë°ì´í„°ì…‹ ìë™ ìƒì„±

ë‚œì´ë„ ë¶„ë¥˜:
- Level 1 (ì‰¬ì›€): ë‹¨ìˆœ 1-hop ì‚¬ì‹¤ ê²€ìƒ‰
- Level 2 (ì¤‘ê°„): 2-hop ë‹¤ë‹¨ê³„ ì¶”ë¡ 
- Level 3 (ì–´ë ¤ì›€): 3+ hop ë³µì¡í•œ ì¶”ë¡ , ë³µí•© ê´€ê³„
"""
import json
import random
from typing import List, Dict, Optional
from tqdm import tqdm
from neo4j_connector import get_connector
from neo4j_config import Neo4jConfig
from neo4j_query_utils import Neo4jQueryUtils
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ==========================================
# QA í…œí”Œë¦¿ ì •ì˜ (ê´€ê³„ íƒ€ì…ë³„)
# ==========================================

QA_TEMPLATES = {
    # IS_A ê´€ê³„
    "IS_A": [
        ("{{term}}ì€(ëŠ”) ì–´ë–¤ ì¢…ë¥˜ì˜ ê°œë…ì¸ê°€ìš”?", 
         "{{term}}ì€(ëŠ”) {{target}}ì˜ í•˜ìœ„ ê°œë…ì…ë‹ˆë‹¤."),
        ("{{term}}ì˜ ìƒìœ„ ê°œë…ì€ ë¬´ì—‡ì¸ê°€ìš”?", 
         "{{term}}ì˜ ìƒìœ„ ê°œë…ì€ {{target}}ì…ë‹ˆë‹¤."),
        ("{{term}}ì€(ëŠ”) ë¬´ì—‡ìœ¼ë¡œ ë¶„ë¥˜ë˜ë‚˜ìš”?", 
         "{{term}}ì€(ëŠ”) {{target}}ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤."),
    ],
    
    # FINDING_SITE ê´€ê³„
    "FINDING_SITE": [
        ("{{term}}ì€(ëŠ”) ì‹ ì²´ì˜ ì–´ëŠ ë¶€ìœ„ì—ì„œ ë°œìƒí•˜ë‚˜ìš”?", 
         "{{term}}ì€(ëŠ”) {{target}} ë¶€ìœ„ì—ì„œ ë°œìƒí•©ë‹ˆë‹¤."),
        ("{{term}}ì˜ ë°œìƒ ë¶€ìœ„ëŠ” ì–´ë””ì¸ê°€ìš”?", 
         "{{term}}ì˜ ë°œìƒ ë¶€ìœ„ëŠ” {{target}}ì…ë‹ˆë‹¤."),
        ("{{term}}ì€(ëŠ”) ì–´ë””ì— ìœ„ì¹˜í•˜ë‚˜ìš”?", 
         "{{term}}ì€(ëŠ”) {{target}}ì— ìœ„ì¹˜í•©ë‹ˆë‹¤."),
    ],
    
    # CAUSATIVE_AGENT ê´€ê³„
    "CAUSATIVE_AGENT": [
        ("{{term}}ì˜ ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?", 
         "{{term}}ì˜ ì£¼ìš” ì›ì¸ì€ {{target}}ì…ë‹ˆë‹¤."),
        ("{{term}}ì„(ë¥¼) ì¼ìœ¼í‚¤ëŠ” ì›ì¸ ë¬¼ì§ˆì€ ë¬´ì—‡ì¸ê°€ìš”?", 
         "{{term}}ì„(ë¥¼) ì¼ìœ¼í‚¤ëŠ” ì›ì¸ ë¬¼ì§ˆì€ {{target}}ì…ë‹ˆë‹¤."),
        ("ë¬´ì—‡ì´ {{term}}ì„(ë¥¼) ìœ ë°œí•˜ë‚˜ìš”?", 
         "{{target}}ì´(ê°€) {{term}}ì„(ë¥¼) ìœ ë°œí•©ë‹ˆë‹¤."),
    ],
    
    # PATHOLOGICAL_PROCESS ê´€ê³„
    "PATHOLOGICAL_PROCESS": [
        ("{{term}}ì˜ ë³‘íƒœìƒë¦¬í•™ì  ê³¼ì •ì€ ë¬´ì—‡ì¸ê°€ìš”?", 
         "{{term}}ì˜ ë³‘íƒœìƒë¦¬í•™ì  ê³¼ì •ì€ {{target}}ì…ë‹ˆë‹¤."),
        ("{{term}}ì—ì„œ ì¼ì–´ë‚˜ëŠ” ë³‘ë¦¬í•™ì  ê³¼ì •ì€ ë¬´ì—‡ì¸ê°€ìš”?", 
         "{{term}}ì—ì„œëŠ” {{target}} ê³¼ì •ì´ ì¼ì–´ë‚©ë‹ˆë‹¤."),
    ],
    
    # ASSOCIATED_MORPHOLOGY ê´€ê³„
    "ASSOCIATED_MORPHOLOGY": [
        ("{{term}}ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” í˜•íƒœí•™ì  ë³€í™”ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", 
         "{{term}}ì—ì„œëŠ” {{target}}ì˜ í˜•íƒœí•™ì  ë³€í™”ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."),
        ("{{term}}ì˜ íŠ¹ì§•ì ì¸ í˜•íƒœëŠ” ë¬´ì—‡ì¸ê°€ìš”?", 
         "{{term}}ì˜ íŠ¹ì§•ì ì¸ í˜•íƒœëŠ” {{target}}ì…ë‹ˆë‹¤."),
    ],
    
    # CLINICAL_COURSE ê´€ê³„
    "CLINICAL_COURSE": [
        ("{{term}}ì˜ ì„ìƒ ê²½ê³¼ëŠ” ì–´ë–¤ê°€ìš”?", 
         "{{term}}ì€(ëŠ”) {{target}}í•œ ì„ìƒ ê²½ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤."),
        ("{{term}}ì˜ ì§„í–‰ ì–‘ìƒì€ ì–´ë–¤ê°€ìš”?", 
         "{{term}}ì€(ëŠ”) {{target}}í•œ ì–‘ìƒìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤."),
    ],
    
    # DUE_TO ê´€ê³„
    "DUE_TO": [
        ("{{term}}ì€(ëŠ”) ë¬´ì—‡ ë•Œë¬¸ì— ë°œìƒí•˜ë‚˜ìš”?", 
         "{{term}}ì€(ëŠ”) {{target}} ë•Œë¬¸ì— ë°œìƒí•©ë‹ˆë‹¤."),
        ("{{term}}ì˜ ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?", 
         "{{term}}ì€(ëŠ”) {{target}}ë¡œ ì¸í•´ ë°œìƒí•©ë‹ˆë‹¤."),
    ],
}


class QADatasetGenerator:
    """ë‚œì´ë„ë³„ QA ë°ì´í„°ì…‹ ìƒì„±ê¸°"""
    
    def __init__(self, config: Neo4jConfig):
        self.config = config
        self.conn = None
        self.utils = None
        
    def connect(self):
        """Neo4j ì—°ê²°"""
        self.conn = get_connector(self.config)
        self.conn.connect()
        self.utils = Neo4jQueryUtils(self.conn)
        logger.info("âœ… Neo4j ì—°ê²° ì™„ë£Œ")
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.conn:
            self.conn.close()
    
    def __enter__(self):
        self.connect()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
    
    # ==========================================
    # Level 1: ë‹¨ìˆœ 1-hop QA ìƒì„±
    # ==========================================
    
    def generate_level1_qa(self, max_samples: int = 1000) -> List[Dict]:
        """Level 1: ë‹¨ìˆœ 1-hop ì‚¬ì‹¤ ê²€ìƒ‰ QA
        
        ì˜ˆ: "ì¹˜ì•„ ìš°ì‹ì¦ì˜ ì›ì¸ì€?" -> "ì¹˜ì•„ ìš°ì‹ì¦ì˜ ì›ì¸ì€ ë°•í…Œë¦¬ì•„ì…ë‹ˆë‹¤."
        """
        logger.info("ğŸ”¹ Level 1 QA ìƒì„± ì¤‘ (1-hop)...")
        qa_list = []
        
        # ëª¨ë“  Concept ì¡°íšŒ
        all_concepts = self.conn.execute_query("""
            MATCH (c:Concept)
            RETURN c.conceptId as conceptId, c.term as term
            LIMIT 100
        """)
        
        for concept in tqdm(all_concepts, desc="Level 1 QA"):
            concept_id = concept['conceptId']
            concept_term = concept['term']
            
            # ê° ê´€ê³„ íƒ€ì…ë³„ë¡œ QA ìƒì„±
            for rel_type in ["IS_A", "FINDING_SITE", "CAUSATIVE_AGENT", 
                            "PATHOLOGICAL_PROCESS", "ASSOCIATED_MORPHOLOGY"]:
                
                # í•´ë‹¹ ê´€ê³„ íƒ€ì…ì˜ ë°ì´í„° ì¡°íšŒ
                rels = self.utils.get_direct_relationships(
                    concept_id, 
                    direction="outgoing", 
                    rel_type=rel_type
                )
                
                if not rels or rel_type not in QA_TEMPLATES:
                    continue
                
                # í…œí”Œë¦¿ ì„ íƒ ë° QA ìƒì„±
                for rel in rels[:2]:  # ê° ê´€ê³„ë‹¹ ìµœëŒ€ 2ê°œ
                    template = random.choice(QA_TEMPLATES[rel_type])
                    q_template, a_template = template
                    
                    question = q_template.replace("{{term}}", concept_term)\
                                        .replace("{{target}}", rel['target_term'])
                    answer = a_template.replace("{{term}}", concept_term)\
                                      .replace("{{target}}", rel['target_term'])
                    
                    qa_list.append({
                        "id": f"L1_{len(qa_list)}",
                        "level": 1,
                        "difficulty": "easy",
                        "question": question,
                        "answer": answer,
                        "source_concept": concept_term,
                        "relation_type": rel_type,
                        "target_concept": rel['target_term'],
                        "metadata": {
                            "hops": 1,
                            "relation": rel_type
                        }
                    })
                    
                    if len(qa_list) >= max_samples:
                        break
            
            if len(qa_list) >= max_samples:
                break
        
        logger.info(f"  âœ“ Level 1 QA {len(qa_list)}ê°œ ìƒì„± ì™„ë£Œ")
        return qa_list
    
    # ==========================================
    # Level 2: 2-hop QA ìƒì„±
    # ==========================================
    
    def generate_level2_qa(self, max_samples: int = 500) -> List[Dict]:
        """Level 2: 2-hop ë‹¤ë‹¨ê³„ ì¶”ë¡  QA
        
        ì˜ˆ: "ì¹˜ì•„ ìš°ì‹ì¦ì˜ ìƒìœ„ ê°œë…ì˜ ë°œìƒ ë¶€ìœ„ëŠ”?" 
            -> "ì¹˜ì•„ ìš°ì‹ì¦ì€ ì§ˆë³‘ì´ê³ , ì§ˆë³‘ì€ êµ¬ê°•ì—ì„œ ë°œìƒí•©ë‹ˆë‹¤."
        """
        logger.info("ğŸ”¹ Level 2 QA ìƒì„± ì¤‘ (2-hop)...")
        qa_list = []
        
        # 2-hop ê²½ë¡œ ì¡°íšŒ
        query = """
        MATCH path = (start:Concept)-[r1]->(middle:Concept)-[r2]->(end:Concept)
        WHERE start.term CONTAINS 'caries' OR start.term CONTAINS 'dental'
        RETURN start.term as start_term,
               type(r1) as rel1_type,
               r1.typeTerm as rel1_term,
               middle.term as middle_term,
               type(r2) as rel2_type,
               r2.typeTerm as rel2_term,
               end.term as end_term
        LIMIT 200
        """
        
        paths = self.conn.execute_query(query)
        
        for path in tqdm(paths, desc="Level 2 QA"):
            # 2-hop ì¶”ë¡  QA ìƒì„±
            question = f"{path['start_term']}ì˜ {path['rel1_term']}ì¸ {path['middle_term']}ì˜ {path['rel2_term']}ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            answer = f"{path['start_term']}ì˜ {path['rel1_term']}ì€ {path['middle_term']}ì´ê³ , " \
                    f"ì´ê²ƒì˜ {path['rel2_term']}ì€ {path['end_term']}ì…ë‹ˆë‹¤."
            
            qa_list.append({
                "id": f"L2_{len(qa_list)}",
                "level": 2,
                "difficulty": "medium",
                "question": question,
                "answer": answer,
                "source_concept": path['start_term'],
                "intermediate_concept": path['middle_term'],
                "target_concept": path['end_term'],
                "metadata": {
                    "hops": 2,
                    "relations": [path['rel1_type'], path['rel2_type']],
                    "path": f"{path['start_term']} -> {path['middle_term']} -> {path['end_term']}"
                }
            })
            
            if len(qa_list) >= max_samples:
                break
        
        logger.info(f"  âœ“ Level 2 QA {len(qa_list)}ê°œ ìƒì„± ì™„ë£Œ")
        return qa_list
    
    # ==========================================
    # Level 3: 3+ hop ë³µì¡í•œ QA ìƒì„±
    # ==========================================
    
    def generate_level3_qa(self, max_samples: int = 200) -> List[Dict]:
        """Level 3: 3+ hop ë³µì¡í•œ ì¶”ë¡  QA
        
        ì˜ˆ: "ì¹˜ì•„ ìš°ì‹ì¦ì˜ ì›ì¸ì˜ ìƒìœ„ ë¶„ë¥˜ì˜ íŠ¹ì„±ì€?"
            -> ë‹¤ë‹¨ê³„ ì¶”ë¡  í•„ìš”
        """
        logger.info("ğŸ”¹ Level 3 QA ìƒì„± ì¤‘ (3+ hop)...")
        qa_list = []
        
        # 3-hop ê²½ë¡œ ì¡°íšŒ
        query = """
        MATCH path = (start:Concept)-[*3..3]->(end:Concept)
        WHERE start.term CONTAINS 'caries'
        WITH start, end, 
             [node in nodes(path) | node.term] as node_terms,
             [rel in relationships(path) | type(rel)] as rel_types
        RETURN start.term as start_term,
               end.term as end_term,
               node_terms,
               rel_types
        LIMIT 100
        """
        
        paths = self.conn.execute_query(query)
        
        for path in tqdm(paths, desc="Level 3 QA"):
            # ë³µì¡í•œ ì¶”ë¡  QA ìƒì„±
            question = f"{path['start_term']}ì—ì„œ 3ë‹¨ê³„ ê´€ê³„ë¥¼ í†µí•´ ì—°ê²°ëœ ê°œë…ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            answer = f"{path['start_term']}ì€(ëŠ”) {' -> '.join(path['node_terms'][1:-1])}ì„(ë¥¼) " \
                    f"ê±°ì³ {path['end_term']}ê³¼(ì™€) ì—°ê²°ë©ë‹ˆë‹¤."
            
            qa_list.append({
                "id": f"L3_{len(qa_list)}",
                "level": 3,
                "difficulty": "hard",
                "question": question,
                "answer": answer,
                "source_concept": path['start_term'],
                "target_concept": path['end_term'],
                "metadata": {
                    "hops": 3,
                    "relations": path['rel_types'],
                    "path": " -> ".join(path['node_terms'])
                }
            })
            
            if len(qa_list) >= max_samples:
                break
        
        logger.info(f"  âœ“ Level 3 QA {len(qa_list)}ê°œ ìƒì„± ì™„ë£Œ")
        return qa_list
    
    # ==========================================
    # ë³µí•© ê´€ê³„ QA ìƒì„±
    # ==========================================
    
    def generate_complex_qa(self, max_samples: int = 200) -> List[Dict]:
        """ë³µí•© ê´€ê³„ QA: ì—¬ëŸ¬ ê´€ê³„ë¥¼ ë™ì‹œì— ê³ ë ¤
        
        ì˜ˆ: "ì›ì¸ì´ ë°•í…Œë¦¬ì•„ì´ê³  ì¹˜ì•„ì—ì„œ ë°œìƒí•˜ëŠ” ì§ˆë³‘ì€?"
        """
        logger.info("ğŸ”¹ ë³µí•© ê´€ê³„ QA ìƒì„± ì¤‘...")
        qa_list = []
        
        # ì›ì¸ê³¼ ë¶€ìœ„ë¥¼ ëª¨ë‘ ê°€ì§„ ê°œë…
        query = """
        MATCH (concept:Concept)-[:CAUSATIVE_AGENT]->(agent:Concept)
        MATCH (concept)-[:FINDING_SITE]->(site:Concept)
        WHERE concept.term CONTAINS 'caries' OR concept.term CONTAINS 'dental'
        RETURN concept.term as concept_term,
               agent.term as agent_term,
               site.term as site_term
        LIMIT 100
        """
        
        results = self.conn.execute_query(query)
        
        for result in tqdm(results, desc="Complex QA"):
            # ë³µí•© ì§ˆë¬¸ ìƒì„±
            question = f"ì›ì¸ì´ {result['agent_term']}ì´ê³  {result['site_term']}ì—ì„œ ë°œìƒí•˜ëŠ” ì§ˆë³‘ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            answer = f"{result['concept_term']}ì€(ëŠ”) {result['agent_term']}ì´(ê°€) ì›ì¸ì´ë©° " \
                    f"{result['site_term']}ì—ì„œ ë°œìƒí•˜ëŠ” ì§ˆë³‘ì…ë‹ˆë‹¤."
            
            qa_list.append({
                "id": f"LC_{len(qa_list)}",
                "level": 3,
                "difficulty": "hard",
                "type": "complex",
                "question": question,
                "answer": answer,
                "concept": result['concept_term'],
                "metadata": {
                    "causative_agent": result['agent_term'],
                    "finding_site": result['site_term'],
                    "query_type": "multi_constraint"
                }
            })
            
            if len(qa_list) >= max_samples:
                break
        
        logger.info(f"  âœ“ ë³µí•© QA {len(qa_list)}ê°œ ìƒì„± ì™„ë£Œ")
        return qa_list
    
    # ==========================================
    # ì „ì²´ ë°ì´í„°ì…‹ ìƒì„±
    # ==========================================
    
    def generate_all_qa(self, 
                        level1_samples: int = 1000,
                        level2_samples: int = 500,
                        level3_samples: int = 200,
                        complex_samples: int = 200) -> Dict[str, List[Dict]]:
        """ëª¨ë“  ë‚œì´ë„ì˜ QA ìƒì„±"""
        logger.info("ğŸš€ ì „ì²´ QA ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘...")
        
        dataset = {
            "level1": self.generate_level1_qa(level1_samples),
            "level2": self.generate_level2_qa(level2_samples),
            "level3": self.generate_level3_qa(level3_samples),
            "complex": self.generate_complex_qa(complex_samples)
        }
        
        # í†µê³„ ì¶œë ¥
        total = sum(len(v) for v in dataset.values())
        logger.info("\nğŸ“Š ìƒì„±ëœ QA í†µê³„:")
        logger.info(f"  - Level 1 (ì‰¬ì›€): {len(dataset['level1'])}ê°œ")
        logger.info(f"  - Level 2 (ì¤‘ê°„): {len(dataset['level2'])}ê°œ")
        logger.info(f"  - Level 3 (ì–´ë ¤ì›€): {len(dataset['level3'])}ê°œ")
        logger.info(f"  - Complex (ë³µí•©): {len(dataset['complex'])}ê°œ")
        logger.info(f"  - ì´í•©: {total}ê°œ")
        
        return dataset
    
    # ==========================================
    # ì €ì¥
    # ==========================================
    
    def save_to_jsonl(self, dataset: Dict[str, List[Dict]], output_dir: str = "."):
        """JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        # ë‚œì´ë„ë³„ íŒŒì¼ ì €ì¥
        for level, qa_list in dataset.items():
            output_file = os.path.join(output_dir, f"qa_{level}.jsonl")
            with open(output_file, 'w', encoding='utf-8') as f:
                for qa in qa_list:
                    f.write(json.dumps(qa, ensure_ascii=False) + '\n')
            logger.info(f"  âœ“ {output_file} ì €ì¥ ì™„ë£Œ ({len(qa_list)}ê°œ)")
        
        # ì „ì²´ ë°ì´í„°ì…‹ ì €ì¥
        all_qa = []
        for qa_list in dataset.values():
            all_qa.extend(qa_list)
        
        output_file = os.path.join(output_dir, "qa_all.jsonl")
        with open(output_file, 'w', encoding='utf-8') as f:
            for qa in all_qa:
                f.write(json.dumps(qa, ensure_ascii=False) + '\n')
        logger.info(f"  âœ“ {output_file} ì €ì¥ ì™„ë£Œ (ì´ {len(all_qa)}ê°œ)")
        
        # í†µê³„ íŒŒì¼ ì €ì¥
        stats = {
            "total": len(all_qa),
            "by_level": {k: len(v) for k, v in dataset.items()},
            "by_difficulty": {
                "easy": len(dataset['level1']),
                "medium": len(dataset['level2']),
                "hard": len(dataset['level3']) + len(dataset['complex'])
            }
        }
        
        stats_file = os.path.join(output_dir, "qa_stats.json")
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        logger.info(f"  âœ“ {stats_file} ì €ì¥ ì™„ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Neo4jì—ì„œ ë‚œì´ë„ë³„ QA ë°ì´í„°ì…‹ ìƒì„±")
    parser.add_argument("--output-dir", default="./qa_dataset", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--level1", type=int, default=1000, help="Level 1 ìƒ˜í”Œ ìˆ˜")
    parser.add_argument("--level2", type=int, default=500, help="Level 2 ìƒ˜í”Œ ìˆ˜")
    parser.add_argument("--level3", type=int, default=200, help="Level 3 ìƒ˜í”Œ ìˆ˜")
    parser.add_argument("--complex", type=int, default=200, help="ë³µí•© QA ìƒ˜í”Œ ìˆ˜")
    
    args = parser.parse_args()
    
    # Neo4j ì—°ê²° ì„¤ì •
    config = Neo4jConfig.default()
    
    # QA ìƒì„±
    with QADatasetGenerator(config) as generator:
        dataset = generator.generate_all_qa(
            level1_samples=args.level1,
            level2_samples=args.level2,
            level3_samples=args.level3,
            complex_samples=args.complex
        )
        
        # ì €ì¥
        generator.save_to_jsonl(dataset, args.output_dir)
    
    logger.info("\nâœ… QA ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
    logger.info(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {args.output_dir}/")


if __name__ == "__main__":
    main()

